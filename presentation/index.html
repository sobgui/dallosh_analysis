<!doctype html>
<html lang="fr">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Dallosh Analysis - Présentation Stratégique</title>

    <link rel="stylesheet" href="node_modules/reveal.js/dist/reveal.css">
    <link rel="stylesheet" href="node_modules/reveal.js/dist/theme/black.css">
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="reveal">
        <div class="slides">

            <!-- Slide 1: Titre -->
            <section data-background-gradient="linear-gradient(to bottom right, #1a1a1a, #4a0e0e)">
                <h1>Dallosh Analysis</h1>
                <h3>Analyse des Tweets SAV Free Mobile</h3>
                <p>Restitution des travaux & Perspectives Stratégiques</p>
                <p><small>Bloc CC2 - Novembre 2025</small></p>

                <aside class="notes">
                    Bonjour à tous. Nous sommes ravis de vous présenter aujourd'hui le projet "Dallosh
                    Analysis".<br><br>
                    Ce projet s'inscrit dans le cadre du Bloc CC2 et vise à analyser les tweets du SAV de Free
                    Mobile.<br>
                    L'objectif de cette présentation est double :<br>
                    1. Vous restituer nos travaux techniques sur la collecte et l'analyse des données.<br>
                    2. Vous proposer des perspectives stratégiques pour améliorer la gestion du service client grâce à
                    l'IA.<br><br>
                    Nous sommes une équipe de 6 étudiants et nous allons nous relayer pour vous détailler notre
                    démarche.
                </aside>
            </section>

            <!-- Slide 2: Contexte -->
            <section>
                <h2>Le Défi Initial</h2>
                <div class="container">
                    <div class="col">
                        <ul>
                            <li class="fragment"><strong>Volume Massif :</strong> ~5000 tweets bruts/jour</li>
                            <li class="fragment"><strong>Bruit :</strong> Spam, doublons, messages non pertinents</li>
                            <li class="fragment"><strong>Objectif :</strong> Transformer la donnée brute en outil
                                décisionnel temps réel</li>
                        </ul>
                    </div>
                </div>

                <aside class="notes">
                    Commençons par le contexte. Free Mobile fait face à un défi majeur sur Twitter.<br><br>
                    Chaque jour, c'est environ 5000 tweets qui mentionnent la marque. C'est un flux continu et
                    massif.<br>
                    Le problème, c'est que ce flux est extrêmement bruité. On y trouve de tout : des vraies plaintes,
                    mais aussi du spam, des doublons, des retweets automatiques, ou des messages qui n'ont rien à voir
                    avec le SAV.<br><br>
                    Notre mission était donc claire : comment transformer cette masse de données brutes et désordonnées
                    en un outil décisionnel propre, capable d'aider le SAV en temps réel ?<br>
                    Il fallait filtrer le bruit pour ne garder que l'information utile.
                </aside>
            </section>

            <!-- Slide 3: Architecture Technique -->
            <section>
                <h2>La Réponse Technique</h2>
                <div class="r-stack">
                    <img src="assets/architecture.png" alt="Architecture Diagram" class="fragment fade-out"
                        data-fragment-index="0">
                    <div class="fragment fade-in-then-out" data-fragment-index="0">
                        <h3>Architecture Microservices</h3>
                        <ul>
                            <li><strong>Orchestration :</strong> RabbitMQ (Événementiel)</li>
                            <li><strong>Backend :</strong> Node.js / Python</li>
                            <li><strong>Frontend :</strong> Next.js / React</li>
                        </ul>
                    </div>
                </div>
                <p class="fragment">Pipeline ETL : Nettoyage Regex &rarr; Déduplication &rarr; Enrichissement IA</p>

                <aside class="notes">
                    Pour répondre à ce défi, nous avons conçu une architecture technique robuste, basée sur des
                    microservices.<br><br>
                    (Montrer le schéma)<br>
                    Comme vous le voyez, nous utilisons RabbitMQ pour orchestrer les échanges entre nos différents
                    services Python et Node.js. Cela nous permet de traiter les tweets de manière asynchrone et
                    résiliente.<br><br>
                    Le cœur du système est notre pipeline ETL (Extract, Transform, Load) :<br>
                    1. D'abord un nettoyage technique (Regex).<br>
                    2. Ensuite une déduplication pour éliminer les répétitions.<br>
                    3. Et enfin, l'étape clé : l'enrichissement par Intelligence Artificielle pour comprendre le sens
                    des messages.
                </aside>
            </section>

            <!-- Slide 4: Pipeline de Traitement -->
            <section>
                <h2>Pipeline de Données</h2>
                <ol>
                    <li class="fragment"><strong>Ingestion :</strong> Lecture des flux Twitter</li>
                    <li class="fragment"><strong>Nettoyage :</strong> Suppression émojis, masquage PII</li>
                    <li class="fragment"><strong>Déduplication :</strong> Méthode IQR (Interquartile Range)</li>
                    <li class="fragment"><strong>Enrichissement IA :</strong>
                        <ul>
                            <li>Sentiment (Positif/Négatif)</li>
                            <li>Priorité (0-2)</li>
                            <li>Topic (Réseau, Facture, etc.)</li>
                        </ul>
                    </li>
                </ol>

                <aside class="notes">
                    Rentrons un peu plus dans le détail de ce pipeline.<br><br>
                    1. L'ingestion récupère les flux en continu.<br>
                    2. Le nettoyage est crucial : on retire les émojis qui polluent l'analyse et surtout, on masque les
                    données personnelles (PII) pour respecter la vie privée.<br>
                    3. Pour la déduplication, nous utilisons une méthode statistique (IQR) qui nous permet d'identifier
                    et d'écarter les outliers et les doublons massifs.<br>
                    4. Enfin, l'IA analyse chaque tweet pour lui attribuer trois méta-données :<br>
                    - Le sentiment (est-ce que le client est content ?)<br>
                    - La priorité (est-ce urgent ?)<br>
                    - Et le sujet (parle-t-on de réseau, de facture, ou d'autre chose ?).
                </aside>
            </section>

            <!-- Slide 5: Dashboard & KPI -->
            <section>
                <h2>Santé du SAV (KPI)</h2>
                <div style="display: flex; align-items: center;">
                    <div style="flex: 1;">
                        <img src="assets/dashboard.png" alt="Dashboard KPI">
                    </div>
                    <div style="flex: 1; font-size: 0.8em;">
                        <ul>
                            <li><strong>NSS (Net Sentiment Score) :</strong> Détection des dérives</li>
                            <li><strong>Volume de Crise :</strong> Tweets à Priorité Haute (>1h)</li>
                            <li><strong>Engagement :</strong> Corrélation Négativité / Viralité</li>
                        </ul>
                    </div>
                </div>

                <aside class="notes">
                    Tout ce traitement nous permet d'alimenter ce Tableau de Bord Global.<br><br>
                    Nous suivons ici des indicateurs clés (KPI) pour piloter le SAV :<br>
                    - Le NSS (Net Sentiment Score) : C'est notre baromètre. Même s'il est souvent négatif dans les
                    télécoms, c'est sa variation qui nous intéresse pour détecter une dérive.<br>
                    - Le Volume de Crise : Ce sont les tweets marqués "Priorité Haute" qui n'ont pas été traités depuis
                    plus d'une heure. C'est l'indicateur d'alerte immédiate.<br>
                    - Enfin, l'Engagement : Nous surveillons la viralité des plaintes. Un tweet négatif qui est beaucoup
                    retweeté devient un risque d'image majeur.
                </aside>
            </section>

            <!-- Slide 6: Analyse des Topics -->
            <section>
                <h2>Carte de Chaleur des Incidents</h2>
                <img src="assets/topics.png" alt="Topics Heatmap" style="max-height: 400px;">
                <div style="font-size: 0.7em; display: flex; justify-content: space-around;">
                    <div style="color: #ff4d4d;">Réseau / Fibre<br>(Critique)</div>
                    <div style="color: #ffcc00;">Administratif<br>(Neutre/Négatif)</div>
                    <div style="color: #66ff66;">Nouveaux Abonnés<br>(Positif)</div>
                </div>

                <aside class="notes">
                    L'analyse par thématique nous donne cette "Carte de Chaleur".<br><br>
                    Ce qu'on observe très clairement :<br>
                    - En Rouge : Le sujet "Réseau / Fibre" concentre la majorité des critiques et des urgences. C'est le
                    point noir.<br>
                    - En Jaune : Les sujets administratifs (factures, forfaits) génèrent un sentiment plus mitigé,
                    souvent de l'incompréhension plutôt que de la colère.<br>
                    - En Vert : Les seuls signaux positifs viennent des "Nouveaux Abonnés" (livraison de box,
                    activation), ce qui prouve que l'expérience d'acquisition est bonne, mais que la fidélisation est
                    plus dure.
                </aside>
            </section>

            <!-- Slide 7: Analyse Temporelle -->
            <section>
                <h2>Anticipation des Crises</h2>
                <img src="assets/timeline.png" alt="Timeline Sentiment">
                <p class="fragment">Corrélation forte : Hausse Volume + Baisse Sentiment = <strong>Panne
                        Nationale</strong></p>

                <aside class="notes">
                    Sur l'axe temporel, nous avons découvert une corrélation très forte qui nous sert d'outil
                    prédictif.<br><br>
                    Regardez ce graphique : quand la courbe de volume (en bleu) monte brutalement et que simultanément
                    la courbe de sentiment (en rouge) s'effondre, c'est la signature indiscutable d'une panne
                    nationale.<br><br>
                    Cela nous permet d'alerter les équipes techniques avant même que leurs propres sondes ne remontent
                    l'information parfois, simplement par la réaction massive des utilisateurs.
                </aside>
            </section>

            <!-- Slide 8: Recommandations Opérationnelles -->
            <section>
                <h2>Nouveaux Usages Métier</h2>
                <div class="r-grid" style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">
                    <div class="card fragment">
                        <h4>Filtrage Prioritaire</h4>
                        <p>Traitement exclusif des tweets "High Priority"</p>
                    </div>
                    <div class="card fragment">
                        <h4>Routage Intelligent</h4>
                        <p>Aiguillage auto par Topic (Tech vs Commerce)</p>
                    </div>
                    <div class="card fragment">
                        <h4>Monitoring Crise</h4>
                        <p>Alerte si >30% priorité haute en 1h</p>
                    </div>
                    <div class="card fragment">
                        <h4>Formation</h4>
                        <p>Évolution des agents vers la résolution complexe</p>
                    </div>
                </div>

                <aside class="notes">
                    Forts de ces analyses, nous formulons 4 recommandations opérationnelles pour Free :<br><br>
                    1. Filtrage Prioritaire : Les agents ne doivent plus lire le flux en vrac. Ils ne doivent traiter
                    que les tweets marqués "High Priority" par l'IA. On élimine le bruit.<br>
                    2. Routage Intelligent : L'IA sait si c'est un problème technique ou commercial. On peut donc
                    aiguiller le ticket directement vers le bon service, sans tri manuel.<br>
                    3. Monitoring de Crise : On met en place une alerte automatique. Si plus de 30% des tweets sont
                    prioritaires sur une heure, on déclenche une cellule de crise.<br>
                    4. Formation : Comme l'IA gère le tri simple, les agents doivent monter en compétence pour gérer des
                    cas plus complexes et émotionnels.
                </aside>
            </section>

            <!-- Slide 9: Stratégie FinOps -->
            <section>
                <h2>Stratégie FinOps & Infra</h2>
                <p>Approche "Modèle le moins cher suffisant"</p>
                <table style="font-size: 0.6em;">
                    <thead>
                        <tr>
                            <th>Priorité</th>
                            <th>Modèle</th>
                            <th>Coût</th>
                            <th>Usage</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr class="fragment">
                            <td>1 (Défaut)</td>
                            <td>Gemini 1.5 Flash</td>
                            <td>Très Faible</td>
                            <td>Tri de masse</td>
                        </tr>
                        <tr class="fragment">
                            <td>2</td>
                            <td>Mistral Small</td>
                            <td>Faible</td>
                            <td>Souveraineté</td>
                        </tr>
                        <tr class="fragment">
                            <td>3</td>
                            <td>GPT-4o-mini</td>
                            <td>Moyen</td>
                            <td>Analyse complexe</td>
                        </tr>
                    </tbody>
                </table>

                <aside class="notes">
                    Pour rendre ce système viable économiquement, nous avons adopté une stratégie FinOps
                    rigoureuse.<br><br>
                    Notre principe est le "Modèle le moins cher suffisant". Pas besoin d'une IA de génie pour classer un
                    spam.<br><br>
                    - Pour le tri de masse (90% du flux), nous utilisons Gemini Flash, qui est extrêmement rapide et peu
                    coûteux.<br>
                    - Pour des besoins de souveraineté ou de traitement intermédiaire, nous privilégions Mistral.<br>
                    - Nous ne réservons les modèles plus coûteux comme GPT-4 que pour les cas très ambigus ou
                    complexes.<br>
                    Cette approche hybride optimise drastiquement nos coûts de fonctionnement.
                </aside>
            </section>

            <!-- Slide 10: Infrastructure Hybride -->
            <section>
                <h2>Infrastructure Hybride</h2>
                <div style="display: flex; justify-content: center; gap: 50px;">
                    <div class="fragment fade-up">
                        <h3>Actuel</h3>
                        <p>On-Premise (Bare Metal)</p>
                        <p><small>Coût marginal nul</small></p>
                    </div>
                    <div class="fragment fade-up">
                        <h3>Cible</h3>
                        <p>Cloud Public (AWS/Azure)</p>
                        <p><small>Scalabilité & Load Balancing</small></p>
                    </div>
                </div>
                <p class="fragment" style="margin-top: 30px; color: #ffcc00;"><strong>PCA :</strong> Fallback sur GPU
                    internes en cas de panne API</p>

                <aside class="notes">
                    Côté infrastructure, nous recommandons une évolution vers l'hybride.<br><br>
                    - Actuellement, nous sommes sur du On-Premise, ce qui est très économique.<br>
                    - Mais pour gérer les pics de charge (les fameuses pannes nationales), nous devons pouvoir déborder
                    sur le Cloud Public (AWS ou Azure) pour absorber le volume.<br><br>
                    Point crucial : nous avons prévu un PCA (Plan de Continuité d'Activité). Si les API externes
                    (OpenAI, Google) tombent, nous basculons automatiquement sur nos propres serveurs GPU avec des
                    modèles Open Source locaux. Le service ne s'arrête jamais.
                </aside>
            </section>

            <!-- Slide 11: RGPD & Souveraineté -->
            <section>
                <h2>RGPD & Souveraineté</h2>
                <div style="display: flex; align-items: center;">
                    <div style="flex: 1;">
                        <ul style="font-size: 0.8em;">
                            <li class="fragment"><strong>Zero Data Retention :</strong> Accords "Entreprise" avec
                                fournisseurs IA</li>
                            <li class="fragment"><strong>Anonymisation :</strong> PII Scrubbing pour API publiques</li>
                            <li class="fragment"><strong>RBAC :</strong> Gestion fine des droits d'accès</li>
                        </ul>
                    </div>
                    <div style="flex: 1;">
                        <img src="assets/users.png" alt="User Management">
                    </div>
                </div>

                <aside class="notes">
                    La sécurité des données est primordiale.<br><br>
                    Nous avons mis en place trois niveaux de protection :<br>
                    1. Nous négocions des accords "Zero Data Retention" avec nos fournisseurs d'IA pour qu'ils
                    n'utilisent pas nos données pour entraîner leurs modèles.<br>
                    2. Si nous devons utiliser une API publique standard, nous appliquons un "PII Scrubbing" : un script
                    qui efface automatiquement les noms, téléphones et adresses avant l'envoi.<br>
                    3. En interne, l'accès aux données est cloisonné par un système de rôles (RBAC) strict.
                </aside>
            </section>

            <!-- Slide 12: Interface d'Administration -->
            <section>
                <h2>Pilotage & Configuration</h2>
                <img src="assets/admin.png" alt="Admin Interface">
                <p><small>Configuration dynamique des modèles et seuils d'alerte</small></p>

                <aside class="notes">
                    Enfin, voici l'interface d'administration que nous avons développée.<br><br>
                    Elle permet aux équipes techniques de piloter toute la solution :<br>
                    - Changer de modèle d'IA à la volée (passer de Gemini à Mistral en un clic).<br>
                    - Ajuster les seuils d'alerte.<br>
                    - Surveiller la consommation de tokens et les coûts en temps réel.<br>
                    C'est la tour de contrôle du système.
                </aside>
            </section>

            <!-- Slide 13: Conclusion -->
            <section data-background-gradient="linear-gradient(to top left, #1a1a1a, #0e2a4a)">
                <h2>Conclusion</h2>
                <p>Dallosh Analysis transforme le <strong>bruit</strong> en <strong>stratégie</strong>.</p>
                <ul>
                    <li class="fragment">Gain de productivité majeur</li>
                    <li class="fragment">Maîtrise des coûts (FinOps)</li>
                    <li class="fragment">Respect de la souveraineté des données</li>
                </ul>

                <aside class="notes">
                    Pour conclure, Dallosh Analysis n'est pas juste un outil de tri.<br><br>
                    C'est une solution stratégique qui transforme le bruit des réseaux sociaux en information
                    exploitable.<br>
                    Nous apportons un gain de productivité majeur pour le SAV, tout en maîtrisant les coûts grâce au
                    FinOps et en garantissant la souveraineté des données de Free.<br><br>
                    Nous sommes prêts pour le déploiement.
                </aside>
            </section>

            <!-- Slide 14: Fin -->
            <section>
                <h1>Merci</h1>
                <p>Projet réalisé par :</p>
                <ul style="list-style: none; font-size: 0.8em;">
                    <li>Oumar BEN LOLO</li>
                    <li>Gauthier</li>
                    <li>Vincent</li>
                    <li>Yassine</li>
                    <li>Yacine</li>
                    <li>Kais</li>
                </ul>
                <p style="margin-top: 30px;"><small><a href="https://dallosh-analysis.agglomy.com/"
                            target="_blank">dallosh-analysis.agglomy.com</a></small></p>

                <aside class="notes">
                    Merci de votre attention.<br><br>
                    Ce projet a été réalisé par Oumar, Gauthier, Vincent, Yassine, Yacine et Kais.<br>
                    Nous sommes maintenant disponibles pour répondre à toutes vos questions.
                </aside>
            </section>

        </div>
    </div>

    <script src="node_modules/reveal.js/dist/reveal.js"></script>
    <script>
        Reveal.initialize({
            hash: true,
            slideNumber: true,
            transition: 'convex', // none/fade/slide/convex/concave/zoom
            autoPlayMedia: true,
            plugins: [] // Add plugins if needed, but basic setup works without
        });
    </script>
</body>

</html>