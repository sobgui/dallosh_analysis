# Production deployment

services:
  # Traefik Reverse Proxy
  traefik:
    image: traefik:v3.5
    container_name: traefik
    command:
      - "--api.insecure=true"                          # Enables web dashboard (optional, use in dev only)
      - "--providers.docker=true"                      # Enable Docker provider for service discovery
      - "--providers.docker.exposedbydefault=false"   # Only expose containers with traefik.enable=true label
      - "--entrypoints.web.address=:8080"              # Listen on port 8080 to avoid conflict with app panel on port 80
      - "--log.level=INFO"
    ports:
      - "8080:8080"     # Traefik dashboard (optional)
      # Notice no 80:80 binding - your other panel uses port 80
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    networks:
      - dallosh_network
    restart: unless-stopped

  # RabbitMQ Message Broker
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: dallosh_rabbitmq
    hostname: rabbitmq
    ports:
      - "5672:5672"   # AMQP port
      - "15672:15672" # Management UI port
      - "15674:15674" # Web STOMP port (for browser WebSocket connections)
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin123
    volumes:
      - ./rabbitmq/data:/var/lib/rabbitmq
    networks:
      - dallosh_network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    command: >
      sh -c "rabbitmq-plugins enable rabbitmq_web_stomp rabbitmq_web_stomp_examples &&
             rabbitmq-server"

  # MongoDB Database
  mongodb:
    image: mongo:4.4
    container_name: dallosh_mongodb
    ports:
      - "27019:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin123
    volumes:
      - ./mongodb/data:/data/db
      - ./mongodb/config:/data/configdb
    networks:
      - dallosh_network
    healthcheck:
      test: ["CMD-SHELL", "mongo --quiet --eval 'db.adminCommand(\"ping\")' mongodb://admin:admin123@localhost:27017/admin?authSource=admin || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  # Ollama LLM Server
  ollama:
    image: ollama/ollama:latest
    container_name: dallosh_ollama
    ports:
      - "11434:11434"
    volumes:
      - ./models/ollama:/root/.ollama
    networks:
      - dallosh_network
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "ollama serve &
       sleep 10 &&
       until ollama list > /dev/null 2>&1; do
         echo 'Waiting for Ollama server to start...'
         sleep 2
       done &&
       echo 'Ollama server is ready. Pulling llama3.2:1b model...' &&
       ollama pull llama3.2:1b &&
       echo 'Model pulled successfully. Keeping server running...' &&
       wait"
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  # Shared image builder for microservices
  # This service builds the image dallosh_microservice_datasets:latest
  # Worker and listener services will use this same image (no build duplication)
  microservice_datasets:
    build:
      context: ./microservices/auto_processing_datasets
      dockerfile: Dockerfile
    image: dallosh_microservice_datasets:latest
    # This service only builds the image - it exits immediately after building
    # The container won't stay running, but the image will be available
    command: ["sh", "-c", "echo 'Microservice image built: dallosh_microservice_datasets:latest' && exit 0"]
    restart: "no"
    networks:
      - dallosh_network

  # Celery Worker for Microservice
  # Uses the shared image built by microservice_datasets (NO build section - avoids duplication)
  microservice_celery_worker:
    image: dallosh_microservice_datasets:latest
    container_name: dallosh_celery_worker
    command: /bin/bash start_worker.sh
    env_file:
      - ./microservices/auto_processing_datasets/.env
    volumes:
      - ./storage:/project/auto_processing_datasets/storage
      - ./storage:/project/backend/storage
      - ./microservices/auto_processing_datasets/logs:/project/microservices/auto_processing_datasets/logs
    depends_on:
      microservice_datasets:
        condition: service_started
      rabbitmq:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - dallosh_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep -q '[c]elery.*worker' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 20s

  # Celery Event Listener for Microservice
  # Uses the shared image built by microservice_datasets (NO build section - avoids duplication)
  microservice_celery_listener:
    image: dallosh_microservice_datasets:latest
    container_name: dallosh_celery_listener
    command: python main.py
    env_file:
      - ./microservices/auto_processing_datasets/.env
    volumes:
      - ./storage:/project/auto_processing_datasets/storage
      - ./storage:/project/backend/storage
      - ./microservices/auto_processing_datasets/logs:/project/microservices/auto_processing_datasets/logs
    depends_on:
      microservice_datasets:
        condition: service_started
      rabbitmq:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      microservice_celery_worker:
        condition: service_healthy
    networks:
      - dallosh_network
    restart: unless-stopped

  # Backend API Server
  dallosh_analysis_server:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: dallosh_backend
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.backend.rule=Host(`dallosh-analysis-server.agglomy.com`)"
      - "traefik.http.routers.backend.entrypoints=web"
      - "traefik.http.services.backend.loadbalancer.server.port=5006"
    ports:
      - "5006:5006"
    env_file:
      - ./backend/.env
    volumes:
      - ./storage:/project/backend/storage
      - ./backend/logs:/project/backend/logs
    depends_on:
      mongodb:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    networks:
      - dallosh_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "exit 0"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  # Frontend Next.js Client
  dallosh_analysis_client:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: dallosh_frontend
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`dallosh-analysis-client.agglomy.com`)"
      - "traefik.http.routers.frontend.entrypoints=web"
      - "traefik.http.services.frontend.loadbalancer.server.port=3006"
    ports:
      - "3006:3006"
    env_file:
      - ./frontend/.env.production
    depends_on:
      dallosh_analysis_server:
        condition: service_healthy
    networks:
      - dallosh_network
    restart: unless-stopped

# Named volumes for persistent data
volumes:
  rabbitmq_data:
    driver: local
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local
  ollama_data:
    driver: local

# Network for service communication
networks:
  dallosh_network:
    driver: bridge
